{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ec4ba3-d8ab-4964-8f9d-d86efeb0afb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import json\n",
    "import os\n",
    "import os.path\n",
    "import shutil\n",
    "import pandas\n",
    "from joblib import dump, load\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1526ee14-1518-4b7f-9a0d-df479d1b804b",
   "metadata": {},
   "outputs": [],
   "source": [
    "owd = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1f1fa7-f27f-47a0-9ff0-ac1167457a17",
   "metadata": {},
   "source": [
    "# Ingest JSON Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0ce596-25d7-4e60-9d2a-3000c12a5c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set current working directory to json data\n",
    "os.chdir(owd)\n",
    "os.chdir(\"/data/live/json\")\n",
    "# Store filenames of all files in the directory to files.\n",
    "files = []\n",
    "for path in os.listdir(os.getcwd()):\n",
    "    # check if current path is a file\n",
    "    if os.path.isfile(os.path.join(os.getcwd(), path)):\n",
    "        files.append(path)\n",
    "\n",
    "messages = []\n",
    "for file_name in files:\n",
    "    with open(file_name,\"r\") as read_file:\n",
    "        data = json.load(read_file)\n",
    "        if len(data['participants']) == 2:\n",
    "            person_order = 0\n",
    "            if (\"Ethan L\" in data['participants'][person_order].get('name')):\n",
    "                person_order = 1\n",
    "            contact = data['participants'][person_order].get('name')\n",
    "            conversation = pandas.DataFrame(data['messages'])\n",
    "            conversation['Contact'] = contact\n",
    "            messages.append(conversation)\n",
    "\n",
    "messages = pandas.concat(messages, ignore_index=True)\n",
    "messages[\"datetime\"] = pandas.to_datetime(messages.timestamp_ms, unit='ms')\n",
    "\n",
    "os.chdir(owd)\n",
    "os.chdir(\"/data/live/csv\")\n",
    "messages.to_csv(\"messages.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f617d631-6bf4-4c8d-af99-946f4abceabb",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd97963-2d96-43e7-9a6a-cd8dea3f5a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('nps_chat')\n",
    "posts = nltk.corpus.nps_chat.xml_posts()\n",
    "\n",
    "\n",
    "posts_text = [post.text for post in posts]\n",
    "\n",
    "#divide train and test in 80 20\n",
    "train_text = posts_text[:int(len(posts_text)*0.8)]\n",
    "test_text = posts_text[int(len(posts_text)*0.2):]\n",
    "\n",
    "#Get TFIDF features\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,3), \n",
    "                             min_df=0.001, \n",
    "                             max_df=0.7, \n",
    "                             analyzer='word')\n",
    "\n",
    "X_train = vectorizer.fit_transform(train_text)\n",
    "X_test = vectorizer.transform(test_text)\n",
    "\n",
    "y = [post.get('class') for post in posts]\n",
    "\n",
    "y_train = y[:int(len(posts_text)*0.8)]\n",
    "y_test = y[int(len(posts_text)*0.2):]\n",
    "\n",
    "# Fitting Gradient Boosting classifier to the Training set\n",
    "#Can be improved with Cross Validation\n",
    "gb = GradientBoostingClassifier(n_estimators = 400, random_state=0)\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "predictions_rf = gb.predict(X_test)\n",
    "print(classification_report(y_test, predictions_rf))\n",
    "\n",
    "# Save model to directory.\n",
    "os.chdir(owd)\n",
    "# dump(gb,'gradient_boosted_post_class.joblib')\n",
    "os.chdir(owd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e32cd9-43dd-4f70-880e-f29091f3c76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict message type\n",
    "clean_messages = ['a statement' if type(i)==float else i for i in messages['content'].to_list()]\n",
    "vectorized_messages = vectorizer.transform(clean_messages)\n",
    "gb_text_predictions = gb.predict(vectorized_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c2c7fe-fcc3-4262-84eb-2124bbcbcde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages['type_prediction'] = gb_text_predictions\n",
    "messages.to_csv('messages.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d7e763-9a46-4ac6-92ac-cc808bc99d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages['datetime'].min().date()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
